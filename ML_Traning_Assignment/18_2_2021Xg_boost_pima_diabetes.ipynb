{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn as sklearn\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\Shyam Adsul\\Python codes SSPU\\Data sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skinfold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Is Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of times pregnant  Plasma glucose concentration  \\\n",
       "0                         6                           148   \n",
       "1                         1                            85   \n",
       "2                         8                           183   \n",
       "3                         1                            89   \n",
       "4                         0                           137   \n",
       "\n",
       "   Diastolic blood pressure (mm Hg)  Triceps skinfold thickness (mm)  \\\n",
       "0                                72                               35   \n",
       "1                                66                               29   \n",
       "2                                64                                0   \n",
       "3                                66                               23   \n",
       "4                                40                               35   \n",
       "\n",
       "   2-Hour serum insulin (mu U/ml)  \\\n",
       "0                               0   \n",
       "1                               0   \n",
       "2                               0   \n",
       "3                              94   \n",
       "4                             168   \n",
       "\n",
       "   Body mass index (weight in kg/(height in m)^2)  Diabetes pedigree function  \\\n",
       "0                                            33.6                       0.627   \n",
       "1                                            26.6                       0.351   \n",
       "2                                            23.3                       0.672   \n",
       "3                                            28.1                       0.167   \n",
       "4                                            43.1                       2.288   \n",
       "\n",
       "   Age  Is Diabetic  \n",
       "0   50            1  \n",
       "1   31            0  \n",
       "2   32            1  \n",
       "3   21            0  \n",
       "4   33            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Number of times pregnant                        768 non-null    int64  \n",
      " 1   Plasma glucose concentration                    768 non-null    int64  \n",
      " 2   Diastolic blood pressure (mm Hg)                768 non-null    int64  \n",
      " 3   Triceps skinfold thickness (mm)                 768 non-null    int64  \n",
      " 4   2-Hour serum insulin (mu U/ml)                  768 non-null    int64  \n",
      " 5   Body mass index (weight in kg/(height in m)^2)  768 non-null    float64\n",
      " 6   Diabetes pedigree function                      768 non-null    float64\n",
      " 7   Age                                             768 non-null    int64  \n",
      " 8   Is Diabetic                                     768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skinfold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Is Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of times pregnant  Plasma glucose concentration  \\\n",
       "count                768.000000                    768.000000   \n",
       "mean                   3.845052                    120.894531   \n",
       "std                    3.369578                     31.972618   \n",
       "min                    0.000000                      0.000000   \n",
       "25%                    1.000000                     99.000000   \n",
       "50%                    3.000000                    117.000000   \n",
       "75%                    6.000000                    140.250000   \n",
       "max                   17.000000                    199.000000   \n",
       "\n",
       "       Diastolic blood pressure (mm Hg)  Triceps skinfold thickness (mm)  \\\n",
       "count                        768.000000                       768.000000   \n",
       "mean                          69.105469                        20.536458   \n",
       "std                           19.355807                        15.952218   \n",
       "min                            0.000000                         0.000000   \n",
       "25%                           62.000000                         0.000000   \n",
       "50%                           72.000000                        23.000000   \n",
       "75%                           80.000000                        32.000000   \n",
       "max                          122.000000                        99.000000   \n",
       "\n",
       "       2-Hour serum insulin (mu U/ml)  \\\n",
       "count                      768.000000   \n",
       "mean                        79.799479   \n",
       "std                        115.244002   \n",
       "min                          0.000000   \n",
       "25%                          0.000000   \n",
       "50%                         30.500000   \n",
       "75%                        127.250000   \n",
       "max                        846.000000   \n",
       "\n",
       "       Body mass index (weight in kg/(height in m)^2)  \\\n",
       "count                                      768.000000   \n",
       "mean                                        31.992578   \n",
       "std                                          7.884160   \n",
       "min                                          0.000000   \n",
       "25%                                         27.300000   \n",
       "50%                                         32.000000   \n",
       "75%                                         36.600000   \n",
       "max                                         67.100000   \n",
       "\n",
       "       Diabetes pedigree function         Age  Is Diabetic  \n",
       "count                  768.000000  768.000000   768.000000  \n",
       "mean                     0.471876   33.240885     0.348958  \n",
       "std                      0.331329   11.760232     0.476951  \n",
       "min                      0.078000   21.000000     0.000000  \n",
       "25%                      0.243750   24.000000     0.000000  \n",
       "50%                      0.372500   29.000000     0.000000  \n",
       "75%                      0.626250   41.000000     1.000000  \n",
       "max                      2.420000   81.000000     1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAADrCAYAAABzVAFmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWxklEQVR4nO3dfZBddX3H8fcnu4AxhSKbJUIgbHQZbKqCdEUtVkUJswQFpbQldSRax4gjIfjQipqCD8xoVaxJcMRYkI0VEKkgliUSHAWfUJIIJkCQhW5KEiTLWpOY8OAm3/5xzsJlPffm7MO55+7u5zVz557zO797zjcM5Mvv/J4UEZiZmQ01pewAzMysMTlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVqLurGkq4E3gxsi4iXpmXfAo5JqxwM/D4ijsv4bS+wE9gDDERER55nTp8+Pdra2kYbupnZpLF27drHI6I161phCQK4CrgMWDlYEBH/MHgs6VJge43fnxQRjw/ngW1tbaxZs2aYYZqZTV6SNlW7VliCiIg7JLVVCUjA3wNvLOr5ZmY2OmX1QfwN8FhEPFjlegC3SloraWEd4zIzs1SRr5hqmQ9cU+P6iRGxVdKhwGpJGyPijqyKaQJZCDBr1qyxj9TMbJKqewtCUjNwJvCtanUiYmv6vQ24ATihRt0VEdERER2trZn9LGZmNgJlvGI6GdgYEZuzLkqaJunAwWPgFGBDHeMzG1P9/f2cf/759Pf3lx2K2bAUliAkXQP8HDhG0mZJ704vnc2Q10uSDpfUnZ7OAH4i6R7gl8DNEbGqqDjNitbV1cX69etZuXLlviubNRBNpOW+Ozo6wsNcrZH09/czf/58nn76aQ444ACuvvpqWlpayg7L7BmS1laba+aZ1GYF6urqYu/evQDs2bPHrQgbV5wgzAp02223MTAwAMDAwACrV68uOSKz/JwgzAp08skn09ycjCZvbm5m7ty5JUdklp8ThFmBFixYwJQpyX9mTU1NnHPOOSVHZJafE4RZgVpaWujs7EQSnZ2d7qC2caWsmdRmk8aCBQvo7e1168HGHScIs4K1tLSwbNmyssMwGza/YjIzs0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAzs0xOEGZmlskJwszMMjlBmJlZJicIMzPLVFiCkHSlpG2SNlSUfULSFkl3p595VX7bKekBST2SLiwqRrN66O/v5/zzz6e/v7/sUMyGpcgWxFVAZ0b5v0fEcemne+hFSU3Al4FTgTnAfElzCozTrFBdXV2sX7+elStXlh2K2bAUliAi4g7gdyP46QlAT0Q8HBFPA9cCZ4xpcGZ10t/fz6pVq4gIVq1a5VaEjStl9EGcJ+nX6SuoF2Rcnwk8UnG+OS0zG3e6urrYu3cvAHv27HErwsaVeieIrwAvBo4DHgUuzaijjLKodkNJCyWtkbSmr69vTII0Gyu33XYbAwMDAAwMDLB69eqSIzLLr64JIiIei4g9EbEX+BrJ66ShNgNHVpwfAWytcc8VEdERER2tra1jG7DZKJ188sk0Nyc7+zY3NzN37tySIzLLr64JQtJhFadvAzZkVLsLOFrSbEn7A2cDN9UjPrOxtmDBAqZMSf4za2pq4pxzzik5IrP8ihzmeg3wc+AYSZslvRv4nKT1kn4NnAR8IK17uKRugIgYAM4Dvg/cD1wXEfcWFadZkVpaWujs7EQSnZ2dtLS0lB2SWW7NRd04IuZnFF9Rpe5WYF7FeTfwJ0NgzcajBQsW0Nvb69aDjTuFJQgzS7S0tLBs2bKywzAbNi+1YWZmmZwgzMwskxOEWcF6eno47bTT6OnpKTsUs2FxgjAr2CWXXMKuXbu45JJLyg7FbFicIMwK1NPTQ29vLwC9vb1uRdi4ss8EIekHecrM7E8NbTW4FWHjSdVhrpKeBzwfmJ4uqje4RtJBwOF1iM1s3BtsPVQ7N2tkteZBvBe4gCQZrOXZBLGDZL8GM9uHtra25ySFtra20mIxG66qr5giYmlEzAY+HBEviojZ6efYiLisjjGajVtLliypeW7WyPY5kzoilkv6a6Ctsn5EeGF7s31ob29/phXR1tZGe3t72SGZ5Zank/obwBeA1wKvTD8dBcdlNmEsWbKEadOmufVg406etZg6gDkRUXXTHjOrrr29nZtvvrnsMMyGLc88iA3AC4sOxMzMGkueFsR04D5JvwSeGiyMiNMLi8rMzEqXJ0F8ouggzMys8eQZxXR7PQIxM7PGss8EIenVwHLgL4D9gSZgV0QcVHBsNo4tX77c6w6ltmzZAsDMmTNLjqQxtLe3s2jRorLDsBzyvGK6DDgb+DbJiKZzgKOLDMpsInniiSfKDsFsRHJtORoRPZKaImIP8HVJPys4Lhvn/H+Iz1q8eDEAS5cuLTkSs+HJkyB2S9ofuFvS54BHgWn7+pGkK4E3A9si4qVp2eeBtwBPAw8B74qI32f8thfYCewBBiLCE/PMzOoszzyId6T1zgN2AUcCf5vjd1cBnUPKVgMvjYiXA78BPlrj9ydFxHFODmZm5cgzimlTevgk8Mm8N46IOyS1DSm7teL0TuCsvPczM7P6yrMW04mSVkv6jaSHBz9j8Ox/Am6pci2AWyWtlbRwDJ5lZmbDlKcP4grgAyR7QuwZi4dK+jgwAHyzSpUTI2KrpEOB1ZI2RsQdVe61EFgIMGvWrLEIz8zMyNcHsT0ibomIbRHRP/gZ6QMlLSDpvH57tQUAI2Jr+r0NuAE4odr9ImJFRHREREdra+tIwzIzsyHytCB+mI4++g7PXYtp3XAfJqkT+Ajw+ojYXaXONGBKROxMj08BPjXcZ5mZ2ejkSRCvSr8rRxMF8MZaP5J0DfAGkj2tNwMXk4xaOoDktRHAnRFxrqTDgf+IiHnADOCG9HozcHVErMr9JzIzszGRZxTTSSO5cUTMzyi+okrdrcC89Phh4NiRPNPMzMZOnrWYPphRvB1YGxF3j3lEZmbWEPJ0UncA5wIz089CkldHX5P0L8WFZmZmZcrTB9ECHB8RfwCQdDFwPfA6kqGvnysuPDMzK0ueFsQskrWTBv0ROCoinqBiVJOZmU0seVoQVwN3Svpuev4W4Jp0COp9hUVmZmalyjOK6dOSuoHXAgLOjYg16eW3FxmcmZmVJ88rJoCpwI6I+BKwSdLs4kIyM7NGkGexvotJZj8PLs29H/CfRQZlZmbly9OCeBtwOsleEIOT2g4sMigzMytfngTxdLqoXsAzayWZmdkElydBXCfpq8DBkt4D3AZ8rdiwzMysbDVHMSlZMe9bwEuAHcAxwEURsboOsZmZWYlqJoiICEk3RsRfkewnbWZmk0SeV0x3Snpl4ZGYmVlDyTOT+iTgXEm9JCOZRNK4eHmRgZmZWbnyJIhTC4/CzMwaTp6lNjZJOp5kqY0AfjqS7UbNzGx8yTOT+iKgi2TZ7+nA1yUtKTowMzMrV55XTPOBV0TEkwCSPgusAy4pMjAzMytXnlFMvcDzKs4PAB4qJBozM2sYeRLEU8C9kq6S9HVgA/AHScskLav2I0lXStomaUNF2SGSVkt6MP1+QZXfdkp6QFKPpAuH+4cyM7PRy5MgbgA+BvwQ+BHwceAWku1G19b43VVA55CyC4EfRMTRwA/S8+eQ1AR8mWT01BxgvqQ5OeI0M7MxlGcUU9dIbhwRd0hqG1J8BvCG9LiLJOF8ZEidE4CeiHgYQNK16e+8e52ZWR3l3TBorMyIiEcB0u9DM+rMBB6pON+clpmZWR3VO0HkoYyyqFpZWihpjaQ1fX19BYZlZja5DCtBSJoi6aBRPO8xSYel9zoM2JZRZzNwZMX5EcDWajeMiBUR0RERHa2traMIzczMKuWZKHe1pIPSjYLuAx6Q9M8jfN5NwIL0eAHw3Yw6dwFHS5otaX/g7PR3ZmZWR3laEHMiYgfwVqAbmAW8Y18/knQN8HPgGEmbJb0b+CwwV9KDwNz0HEmHS+oGiIgB4Dzg+8D9wHURce9w/2BmZjY6eWZS7ydpP5IEcVlE/FFS1T6BQRExv8qlN2XU3QrMqzjvJklGZmZWkjwtiK+SzKaeBtwh6SiS3eXMzGwCyzMPYhlQOWN6k6STigvJzMwaQZ5O6hmSrpB0S3o+h2c7ms3MbILK84rpKpIO48PT898AFxQUj5mZNYg8CWJ6RFwH7IVnRhntKTQqMzMrXZ4EsUtSC+lsZkmvBrYXGpWZmZUuzzDXD5JMVHuxpJ8CrcBZhUZlZmalyzOKaZ2k1wPHkKyT9EBE/LHwyMzMrFT7TBDp/gzzgLa0/imSiIgvFhybmZmVKM8rpu8BTwLrSTuqzcxs4suTII6IiJcXHomZmTWUPKOYbpF0SuGRmJlZQ8nTgrgTuEHSFOCPJB3VERGj2RfCzMwaXJ4EcSnwGmB9ROxzFVczM5sY8rxiehDY4ORgZja55GlBPAr8KF2s76nBQg9zNTOb2PIkiP9JP/unHzMzmwTyzKT+ZD0CMTOzxlI1QUj6UkRcIOl7pAv1VYqI0wuNzMzMSlWrBfGN9PsL9QjEzMwaS9UEERFr08PjImJp5TVJi4HbiwzMzMzKlWeYa9b2ou8c6QMlHSPp7orPDkkXDKnzBknbK+pcNNLnmZnZyNTqg5gP/CMwW9JNFZcOBPpH+sCIeAA4Ln1GE7AFuCGj6o8j4s0jfY6ZmY1OrT6In5HMgZhOMpt60E7g12P0/DcBD0XEpjG6n5mZjZFafRCbgE0ky2wU5WzgmirXXiPpHmAr8OGIuDerkqSFwEKAWbNmFRKkmdlklKcPohCS9gdOB76dcXkdcFREHAssB26sdp+IWBERHRHR0draWkisZmaTUWkJAjgVWBcRjw29EBE7IuIP6XE3sJ+k6fUO0MxsMquaICT9IP3+t4KePZ8qr5ckvVCS0uMTSOIccce4mZkNX61O6sMkvR44XdK1JPtAPCMi1o30oZKeD8wF3ltRdm5638uBs4D3SRoAngDO9mqyZmb1VStBXARcCBwBDF25NYA3jvShEbEbaBlSdnnF8WXAZSO9v5mZjV6tUUzXA9dL+teI+HQdYzIzswaQZzXXT0s6HXhdWvSjiPjvYsMyM7Oy7XMUk6TPAIuB+9LP4rTMzMwmsDwbBp1GsmDfXgBJXcCvgI8WGZiZmZUr7zyIgyuO/7yAOMzMrMHkaUF8BviVpB+SDHV9HW49mJlNeHk6qa+R9CPglSQJ4iMR8duiAzMzs3LlaUEQEY8CN+2zopmZTRhlrsVkZmYNzAnCzMwy1UwQkqZI2lCvYMzMrHHU7IOIiL2S7pE0KyL+t15BjVfLly+np6en7DCswQz+O7F48eKSI7FG097ezqJFi8oOo6o8ndSHAfdK+iWwa7AwIk4vLKpxqqenh7s33M+e5x9SdijWQKY8nSxEvPbhP9n6xCaxpt2/KzuEfcqTID5ZeBQTyJ7nH8ITL5lXdhhm1uCmbuwuO4R9yjMP4nZJRwFHR8Rt6V4OTcWHZmZmZcqzWN97gOuBr6ZFM6mxR7SZmU0MeYa5vh84EdgBEBEPAocWGZSZmZUvT4J4KiKeHjyR1Eyyo5yZmU1geRLE7ZI+BkyVNBf4NvC9YsMyM7Oy5UkQFwJ9wHrgvUA3sKTIoMzMrHx5RjHtTTcJ+gXJq6UHImJUr5gk9QI7gT3AQER0DLkuYCkwD9gNvDMi1o3mmWZmNjz7TBCSTgMuBx4iWe57tqT3RsQto3z2SRHxeJVrpwJHp59XAV9Jv83MrE7yTJS7lOQv8x4ASS8GbgZGmyBqOQNYmbZU7pR0sKTD0mXHzcysDvL0QWwbTA6ph4Fto3xuALdKWitpYcb1mcAjFeeb07I/IWmhpDWS1vT19Y0yLDMzG1S1BSHpzPTwXkndwHUkf7H/HXDXKJ97YkRslXQosFrSxoi4o/LxGb/J7PeIiBXACoCOjg4PvzUzGyO1XjG9peL4MeD16XEf8ILRPDQitqbf2yTdAJwAVCaIzcCRFedHAFtH80wzMxueqgkiIt5VxAMlTQOmRMTO9PgU4FNDqt0EnCfpWpLO6e3ufzAzq688o5hmA4uAtsr6o1juewZwQzKSlWbg6ohYJenc9L6Xk8y1mAf0kAxzLSRZmZlZdXlGMd0IXEEye3rvaB8YEQ8Dx2aUX15xHCRrQJmZWUnyJIgnI2JZ4ZGYmVlDyZMglkq6GLgVeGqw0DObzcwmtjwJ4mXAO4A38uwrpkjPzcxsgsqTIN4GvKhyyW8zM5v48sykvgc4uOA4zMysweRpQcwANkq6i+f2QYx0mKuZmY0DeRLExYVHYWZmDSfPfhC31yMQMzNrLHlmUu/k2YXy9gf2A3ZFxEFFBmZmZuXK04I4sPJc0ltJFtczM7MJLM8opueIiBvxHAgzswkvzyumMytOpwAdVNmbwczMJo48o5gq94UYAHpJtgQ1M7MJLE8fhJfaNjObhGptOXpRjd9FRHy6gHjMzKxB1GpB7Moomwa8G2gBnCDMzCawWluOXjp4LOlAYDHJzm7XApdW+52ZmU0MNfsgJB0CfBB4O9AFHB8R/1ePwMajLVu20LR7O1M3dpcdipk1uKbd/WzZMlB2GDXV6oP4PHAmsAJ4WUT8oW5RmZlZ6Wq1ID5EsnrrEuDjkgbLRdJJ7aU2hpg5cya/faqZJ14yr+xQzKzBTd3YzcyZM8oOo6aqM6kjYkpETI2IAyPioIrPgaNJDpKOlPRDSfdLulfS4ow6b5C0XdLd6afWiCozMytAnolyY20A+FBErEs7v9dKWh0R9w2p9+OIeHMJ8ZmZGSNYi2m0IuLRiFiXHu8E7gdm1jsOMzOrre4JopKkNuAVwC8yLr9G0j2SbpH0lzXusVDSGklr+vr6igrVzGzSKS1BSPoz4L+ACyJix5DL64CjIuJYYDlwY7X7RMSKiOiIiI7W1tbC4jUzm2xKSRCS9iNJDt+MiO8MvR4ROwaH1UZEN7CfpOl1DtPMbFKre4JQMl72CuD+iPhilTovTOsh6QSSOPvrF6WZmZUxiulE4B3Aekl3p2UfA2YBRMTlwFnA+yQNAE8AZ0eE96AwM6ujuieIiPgJyWS7WnUuAy6rT0RmZpal1FFMZmbWuJwgzMwskxOEmZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwskxOEmZllKmOxvgmtaffvmLqxu+wwrIFMeTLZ7mTv80a8lbtNQE27fwfMKDuMmpwgxlB7e3vZIVgD6unZCUD7ixr7LwOrtxkN/3eGE8QYWrRoUdkhWANavHgxAEuXLi05ErPhcR+EmZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy1RKgpDUKekBST2SLsy4LknL0uu/lnR8GXGamU1mdU8QkpqALwOnAnOA+ZLmDKl2KnB0+lkIfKWuQZqZWSkT5U4AeiLiYQBJ1wJnAPdV1DkDWBkRAdwp6WBJh0XEo/UP10Zi+fLl9PT0lB1GQxj85zA4YW6ya29v96TScaKMV0wzgUcqzjenZcOtA4CkhZLWSFrT19c3poGajYWpU6cyderUssMwG7YyWhDKKIsR1EkKI1YAKwA6Ojoy61j9+f8Qzca/MloQm4EjK86PALaOoI6ZmRWojARxF3C0pNmS9gfOBm4aUucm4Jx0NNOrge3ufzAzq6+6v2KKiAFJ5wHfB5qAKyPiXknnptcvB7qBeUAPsBt4V73jNDOb7EpZ7jsiukmSQGXZ5RXHAby/3nGZmdmzPJPazMwyOUGYmVkmJwgzM8vkBGFmZpmU9AdPDJL6gE1lx2GWYTrweNlBmGU4KiJasy5MqARh1qgkrYmIjrLjMBsOv2IyM7NMThBmZpbJCcKsPlaUHYDZcLkPwszMMrkFYWZmmZwgzMwskxOEmZllcoIwM7NMThBmZpbp/wH9NKAhfBGZcQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(y=df['Number of times pregnant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IQR = stats.iqr(df['Number of times pregnant'], interpolation = 'midpoint')\n",
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number of times pregnant'].replace(0,df['Number of times pregnant'].mean(axis=0),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Number of times pregnant'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y=df['Number of times pregnant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IQR = stats.iqr(df['Number of times pregnant'], interpolation = 'midpoint')\n",
    "IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(y=df['Plasma glucose concentration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Plasma glucose concentration'].replace(0,df['Plasma glucose concentration'].mean(axis=0),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    768.000000\n",
       "mean     121.681605\n",
       "std       30.436016\n",
       "min       44.000000\n",
       "25%       99.750000\n",
       "50%      117.000000\n",
       "75%      140.250000\n",
       "max      199.000000\n",
       "Name: Plasma glucose concentration, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Plasma glucose concentration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(y=df['Plasma glucose concentration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    768.000000\n",
       "mean      69.105469\n",
       "std       19.355807\n",
       "min        0.000000\n",
       "25%       62.000000\n",
       "50%       72.000000\n",
       "75%       80.000000\n",
       "max      122.000000\n",
       "Name: Diastolic blood pressure (mm Hg), dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Diastolic blood pressure (mm Hg)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(y=df['Diastolic blood pressure (mm Hg)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Diastolic blood pressure (mm Hg)'].replace(0,df['Diastolic blood pressure (mm Hg)'].mean(axis=0),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAADsCAYAAACbr7puAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXXElEQVR4nO3df3DddZ3v8eerCYLQIhAC0y3WgGF1UQQ0rNeF8erSXrOC5dfCwojNImPR5ZaCMypcGQu7sHJnl16gd92hsLCpCoogSxHM0tYVXOciN1GvRX4sGQharLSmQvlZSPveP77fhNPck5PvOTnf881JX4+ZzDnf7/ecfF86tO9+vp9figjMzMwAZhUdwMzMpg8XBTMzG+OiYGZmY1wUzMxsjIuCmZmNcVEwM7MxrUUHmIoDDzwwOjo6io5hZtZUBgYGfhcR7eWuNXVR6OjooL+/v+gYZmZNRdIzE13z4yMzMxvjomBmZmNcFMzMbIyLgpmZjXFRMMvB8PAwF154IcPDw0VHMauKi4JZDnp7e9mwYQOrV68uOopZVVwUzOpseHiYvr4+IoK+vj63FqypuCiY1Vlvby87d+4EYMeOHW4tWFPJrShIulnSZkmPlJz7O0mPS/qFpLsk7Vdy7VJJg5KekPSxvHKZ5W3dunWMjIwAMDIywtq1awtOZJZdni2Ffwa6x51bC7w3It4H/AdwKYCkI4CzgPek3/mapJYcs5nlZsGCBbS2JosFtLa2snDhwoITmWWXW1GIiAeBrePO3R8RI+nhQ8Ah6fuTgW9FxPaIeBoYBP44r2xmeerp6WHWrOSPVktLC4sXLy44kVl2RfYpfBr4fvp+HvDrkmsb03NmTaetrY3u7m4k0d3dTVtbW9GRzDIrZEE8SV8GRoBvjp4q87GY4LtLgCUA8+fPzyWf2VT19PQwNDTkVoI1nYa3FCT1ACcBn4yI0b/4NwJvL/nYIcBvyn0/IlZFRFdEdLW3l1351axwbW1tXH/99W4lWNNpaFGQ1A18CVgUEa+UXFoDnCVpT0mHAocDDzcym5mZ5fj4SNJtwEeAAyVtBJaTjDbaE1grCeChiPhsRPxS0u3AoySPlS6IiB15ZTMzs/L05hOc5tPV1RXeZMfMrDqSBiKiq9w1z2g2M7MxLgpmZjbGRcHMzMa4KJjlwPspWLNyUTDLgfdTsGblomBWZ95PwZqZi4JZnXk/BWtmkxYFSbMkHSPpREl/KungRgQza1beT8Ga2YRFQdI7Ja0iWcb6auBs4K9IZiM/JOlcSW5pmI3j/RSsmVX6S/1K4BvAOyPiYxFxTkT8ebpBziLgbcCnGhHSrJl4PwVrZhMWhYg4OyIejDLrYETE5oi4NiJ6841n1ny8n4I1s0kXxJN0WpnTLwAbImJz/SOZNb+jjz6aNWvWcPTRRxcdxawqWfoEzgNuAj6Z/twIfB74sSQ/PjIrY8WKFQBcc801BScxq06WorAT+KOIOD0iTgeOALYDHyTZG8HMSvT39/PSSy8B8NJLLzEwMFBwIrPsshSFjoh4ruR4M/CHEbEVeCOfWGbN6/LLL9/lePny5cUEMatBlk12fiTpe8B30uPTgQcl7QM8n1cws2Y12kqY6NhsOstSFC4gKQTHAQJWA3emo5I+mmM2s6Y0e/bsXQrB7NmzC0xjVp1JHx9F4o6IuDgiLkrfN+92bWY5+8xnPrPL8fnnn19QErPqVZrR/KKkbWV+XpS0rZEhzZrJXXfdtcvxnXfeWVASs+pN+PgoIuaMvpf0s4g4pjGRzJrb0NBQxWOz6Szr2kV+XGSWUUdHR8Vjs+nMC9qZ1dmpp566y/Hpp59eUBKz6k34+Gjc8hb7jV/uIiK+m1sqsyZ244037nJ8ww038IlPfKKgNGbVqTQktfS/4gfGHQfgomBWhucpWDOr1NF8biODmM0Unqdgzcx9CmZ1Nn6ZiyuuuKKYIGY1yDKj2SyTlStXMjg4WHSMaWXWrFmsXr16t9+nubOzk6VLlxYdwzJwS8EsB3vuuSfg4ajWfLJsstMCnAh0lH4+IlbkF8uakf8l+KZly5YBcN111xWcxKw6WR4f3QO8Bmwg2VvBzMxmqCxF4ZCIeF/uSczMrHBZ+hS+L+m/VfuLJd0sabOkR0rOHSBpraQn09f9S65dKmlQ0hOSPlbt/czMbOqyFIWHgLskvVrlKqn/DHSPO3cJsD4iDgfWp8dIOgI4C3hP+p2vpX0ZZmbWQFmKwjXAh4C9I2LfiJgTEftO9qWIeBDYOu70yUBv+r4XOKXk/LciYntEPA0MAn+cIZuZmdVRlqLwJPBInTbWOTgiNgGkrwel5+cBvy753Mb0nJmZNVCWjuZNwA8lfR/YPnqyzkNSVeZc2SIkaQmwBGD+/Pl1jGBmZllaCk+TPP9/CzCn5KcWz0maC5C+bk7PbwTeXvK5Q4DflPsFEbEqIroioqu9vb3GGGZmVs6kLYWIqOfCLWuAHuDq9PXukvO3SloB/AFwOPBwHe9rZmYZZJnR3AV8GXgHu85orjh3QdJtwEeAAyVtBJaTFIPbJZ0H/Ao4I/1dv5R0O/AoMAJcEBE7avkfZGZmtcvSp/BN4AtUOaM5Is6e4NIJE3z+KuCqrL/fzMzqL0tR2BIRa3JPYmZmhctSFJZLuomks7l09JF3XjMzm2GyFIVzgXcDe/Dm4yNvx2lmNgNlKQpHRcSRuScxM7PCZVr7KF2byMzMZrgsLYXjgR5JT5P0KQgIL6dtZjbzZCkK41c6NTOzGWrCoiBpdkS8FBHPTPaZfKKZmVmjVepTuFvSNZI+LGmf0ZOSDpN0nqR/xa0IM7MZZcKWQkScIOnjwPnAcekuaSPAE8C9QE9E/LYxMc3MrBEq9ilExH3AfQ3KYmZmBcsyJNXMzHYTLgpmZjbGRcHMzMZkKgqSjpd0bvq+XdKh+cYyM7MiTFoUJC0HvgRcmp7aA/hGnqHMzKwYWVoKpwKLgJcBIuI31L5Hs5mZTWNZisLrEREky2VTOpHNzMxmlixF4XZJNwD7SfoMsA64Md9YZmZWhIqT1yQJ+DbJJjvbgHcBX4mItQ3IZmZmDTbZjOaQ9C8R8QHAhcDMbIbLusnOsbknMTOzwmXZT+GjwPmSniEZgeRNdszMZqgsReHPck9hZmbTQpaiELmnMDOzaSFLUbiXpDAI2As4lGRPhffkmMvMzAowaVGIiCNLjyW9n2TjHTMzm2GqXiU1In4KeDSSmdkMNGlLQdLnSw5nAR8AtuSWyMzMCpOlT6F08bsR4HvAnfnEMTOzImXpU7hi9L2kWcDsiHgt11RmZlaILPsp3Cpp33R11EeBJyR9If9oZmbWaFk6mo+IiG3AKcB9wHzgU1O5qaSLJf1S0iOSbpO0l6QDJK2V9GT6uv9U7mFmZtXLUhT2kLQHSVG4OyLeYAoT2iTNAy4EuiLivUALcBZwCbA+Ig4H1qfHZmbWQFmKwg3AELAP8KCkd5Asoz0VrcBbJbUCewO/AU4GetPrvSRFyMzMGkjJpmpVfklqjYiRmm8qLQOuAl4F7o+IT0p6PiL2K/nM7yOi4iOkrq6u6O/vrzVGXaxcuZLBwcFCM9j0M/rfRGdnZ8FJbLrp7Oxk6dKlhWaQNBARXeWuZZmnsAy4BXgRuAk4huTRzv01htmfpFVwKPA88B1J51Tx/SXAEoD58+fXEqGuBgcH+fkjj7Fj7wOKjmLTyKzXk39sDTz1XMFJbDppeWVr0REmlWWewqcj4jpJHwPagXNJikRNRQFYADwdEVsAJH0X+BPgOUlzI2KTpLnA5nJfjohVwCpIWgo1ZqirHXsfwKvv/njRMcxsmnvr4/cVHWFSWfoUlL5+HLglIv5fybla/Ar4L5L2Trf7PAF4DFgD9KSf6QHunsI9zMysBllaCgOS7id53HOppDnAzlpvGBE/kXQH8FOSGdI/I/mX/2zgdknnkRSOM2q9h5mZ1SZLUTgPOBp4KiJekdRG8gipZhGxHFg+7vR2klaDmZkVJMvjowCOIJlbAMnQ1L1yS2RmZoXJUhS+BnwIODs9fhH4h9wSmZlZYbI8PvpgRLxf0s8AIuL3kt6Scy4zMytAlpbCG5JaSJe2kNTOFDqazcxs+spSFK4H7gIOknQV8O/A3+aayszMClHx8VG6f8LTwBdJRgYJOCUiHmtANjMza7CKRSEidkq6JiI+BDzeoExmZlaQLI+P7pd0ejr72MzMZrAso48+TzI3YYek0W04IyL2zS+WmZkVIcsezXMaEcTMzIqXpaWApNOA40mGpf4oIv4lz1DN5Nlnn6XllReaYvVDMytWyyvDPPtszVvRNMSkfQqSvgZ8FtgAPAJ8VpJnNJuZzUBZWgr/FXhvpFu0SeolKRAGzJs3j99ub/V+CmY2qbc+fh/z5h1cdIyKsow+egIo3eLs7cAv8oljZmZFytJSaAMek/Rwenws8H8krQGIiEV5hTMzs8bKUhS+knsKMzObFrIMSX2gEUHMzKx4WfoUzMxsN+GiYGZmY1wUzMxszIR9CpI2kG6sU05EvC+XRGZmVphKHc0npa8XpK9fT18/CbySWyIzMyvMhEUhIp4BkHRcRBxXcukSST8G/jrvcGZm1lhZ+hT2kXT86IGkPyFZStvMzGaYLJPXzgNulvS29Ph54NO5JTIzs8Jkmbw2ABwlaV9AEfFC/rHMzKwIkxaFtIWwHPhwevwA8NcuDm9qeWWr91OwXcx6bRsAO/fyBoX2ppZXtgLTe5XULI+PbibZR+HM9PhTwC3AaXmFaiadnZ1FR7BpaHDwRQA6D5vefwFYox087f/OyFIU3hkRp5ccXyHp5znlaTpLly4tOoJNQ8uWLQPguuuuKziJWXWyjD56ddzoo+OAV/OLZGZmRcnSUvgc0Jv2LQjYCvTkmsrMzAqRZfTRz3lz9BERsW2qN5W0H3AT8F6SpTQ+TbLD27eBDmAIODMifj/Ve5mZWXaTPj6S9DZJK4AfAD+QdE3JnIVaXQf0RcS7gaOAx4BLgPURcTiwPj02M7MGytKncDPwIsnoozOBbSSjj2qStjg+DPwTQES8HhHPAycDvenHeoFTar2HmZnVpojRR4cBW4BbJB0FDADLgIMjYhNARGySdNAU7mFmZjUoYvRRK/B+4B8j4hjgZap4VCRpiaR+Sf1btmyZQgwzMxsvS1H4HPAPkoYkPQP8b+CzU7jnRmBjRPwkPb6DpEg8J2kuQPq6udyXI2JVRHRFRFd7e/sUYpiZ2XgNH30UEb+V9GtJ74qIJ4ATgEfTnx7g6vT17qncx8zMqldp57XPT3AegIhYMYX7LgW+KektwFPAuSStltslnQf8CjhjCr/fzMxqUKmlMCevm6atj64yl07I655mZja5SjuvXdHIIGZmVrwsk9cOk3SPpC2SNku6W9JhjQhnZmaNlWX00a3A7cBc4A+A7wC35RnKzMyKkaUoKCK+HhEj6c83SNYrMjOzGabS6KMD0rf/JukS4FskxeAvgHsbkM3MzBqs0uijAZIioPT4/JJrAfxNXqHMzKwYlUYfHdrIIGZmVrwsfQpmZrabcFEwM7MxLgpmZjYmy+S1U0t3WpO0n6RTck1lZmaFyNJSWB4RL4wepLukLc8tkZmZFSZLUSj3mSw7tpmZWZPJUhT6Ja2Q9M50HaT/RTKHwczMZpgsRWEp8DrwbZJ1j14DLsgzlJmZFSPLzmtV7aFsZmbNq9LaR9dGxEWS7qHMAngRsSjXZGZm1nCVWgpfT1//vhFBzMyseJXWPhpIXx9oXBwzMytSpcdHGyi/b4KAiIj35ZbKzMwKUenx0UkNS2FmZtNCpcdHz4y+l3QwcGx6+HBEbM47mJmZNV6WtY/OBB4GzgDOBH4i6c/zDmZmZo2XZbmKLwPHjrYOJLUD64A78gxmZmaNl2nto3GPi4Yzfs/MzJpMlpZCn6R/BW5Lj/8C+H5+kczMrChZlrn4gqTTgONJhqOuioi7ck9mZmYNN2lRkPQ/I+JLwHfLnDMzsxkkS9/AwjLn/qzeQczMrHiVZjR/Dvgr4DBJvyi5NAf4cd7BzMys8So9PrqVpEP5q+y6dPaLEbE111RmZlaICR8fRcQLETEEXAb8Np3hfChwjqT9pnpjSS2Sfibpe+nxAZLWSnoyfd1/qvcwM7PqZOlTuBPYIakT+CeSwnBrHe69DHis5PgSYH1EHA6sxxv7mJk1XJaisDMiRoDTgGsj4mJg7lRuKukQ4ETgppLTJwO96fte4JSp3MPMzKqXZfLaG5LOBhYDn0jP7THF+14LfJGk03rUwRGxCSAiNkk6aIr3sAZbuXIlg4ODRceYFkb/f1i2bFnBSaaHzs5Oli5dWnQMyyBLS+Fc4EPAVRHxtKRDgW/UekNJJwGbRzfxqeH7SyT1S+rfsmVLrTHMcrXnnnuyfft23njjjaKjmFVFEeX20cnxhtJXgU8BI8BewL4kE+OOBT6SthLmAj+MiHdV+l1dXV3R39+fd2Szqq1YsYJ77rmHRYsWcfHFFxcdx2wXkgYioqvctSxLZx8u6Q5Jj0p6avSn1jARcWlEHBIRHcBZwA8i4hxgDdCTfqwHuLvWe5gVaXh4mL6+PiKCvr4+hoeHi45kllmWx0e3AP9I8i/7jwKrga/nkOVqYKGkJ0lmUV+dwz3Mctfb28vOnTsB2LFjB6tXry44kVl2WYrCWyNiPcmjpmci4nLgT+tx84j4YUSclL4fjogTIuLw9NUT5KwprVu3jpGREQBGRkZYu3ZtwYnMsstSFF6TNAt4UtJ/l3Qq4JFBZhNYsGABra3JwL7W1lYWLiy3fJjZ9JSlKFwE7A1cCHyApJO4p9IXzHZnPT09zJqV/NFqaWlh8eLFBScyy27SohAR/zciXoqIjRFxbkScFhEPNSKcWTNqa2uju7sbSXR3d9PW1lZ0JLPMKq2Sem1EXCTpHuD/G7caEYtyTWbWxHp6ehgaGnIrwZpOpRnNoyOM/r4RQcxmkra2Nq6//vqiY5hVbcKiMDrjOCIekNSevvcUYjOzGWzCPgUlLpf0O+Bx4D8kbZH0lcbFMzOzRqrU0XwRcBxwbES0RcT+wAeB4yR53r6Z2QxUqSgsBs6OiKdHT0TEU8A56TUzM5thKhWFPSLid+NPpv0KU10628zMpqFKReH1Gq+ZmVmTqjQk9ShJ28qcF8mS12ZmNsNM2FKIiJaI2LfMz5yI8OMjswoGBwc58cQTvROdNZ0sax+ZWZWuvPJKXn75Za688sqio5hVxUXBrM4GBwcZGhoCYGhoyK0FayouCmZ1Nr514NaCNRMXBbM6G20lTHRsNp25KJjVWUdHR8Vjs+nMRcGszi677LKKx2bTmYuCWZ11dnaOtQ46Ojro7OwsNpBZFVwUzHJw2WWXsc8++7iVYE2n0oxmM6tRZ2cn9957b9ExzKrmloKZmY1xUTAzszEuCmY5GB4e5sILL2R4eLjoKGZVcVEwy0Fvby8bNmxg9erVRUcxq4qLglmdDQ8P09fXR0TQ19fn1oI1FRcFszrr7e1l586dAOzYscOtBWsqLgpmdbZu3TpGRkYAGBkZYe3atQUnMsvORcGszhYsWEBrazIFqLW1lYULFxacyCw7FwWzOuvp6WHWrOSPVktLC4sXLy44kVl2LgpmddbW1kZ3dzeS6O7upq2trehIZpk1vChIerukf5P0mKRfSlqWnj9A0lpJT6av+zc6m1m99PT0cOSRR7qVYE1HEdHYG0pzgbkR8VNJc4AB4BTgL4GtEXG1pEuA/SPiS5V+V1dXV/T39+cd2cxsRpE0EBFd5a41vKUQEZsi4qfp+xeBx4B5wMlAb/qxXpJCYWZmDVRon4KkDuAY4CfAwRGxCZLCARxUYDQzs91SYUVB0mzgTuCiiNhWxfeWSOqX1L9ly5b8ApqZ7YYKKQqS9iApCN+MiO+mp59L+xtG+x02l/tuRKyKiK6I6Gpvb29MYDOz3UQRHc0i6TPYGhEXlZz/O2C4pKP5gIj44iS/awvwTJ55zabgQOB3RYcwK+MdEVH2X9VFFIXjgR8BG4Cd6en/QdKvcDswH/gVcEZEbG1oOLM6ktQ/0QgPs+mq4UXBbHfhomDNyDOazcxsjIuCWX5WFR3ArFp+fGRmZmPcUjAzszEuCmZmNsZFwczMxrgomJnZGBcFMzMb85831Bn+1OPFTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(y=df['Diastolic blood pressure (mm Hg)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Triceps skinfold thickness (mm)'].replace(0,df['Triceps skinfold thickness (mm)'].mean(axis=0),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2-Hour serum insulin (mu U/ml)'].replace(0,df['2-Hour serum insulin (mu U/ml)'].median(axis=0),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Body mass index (weight in kg/(height in m)^2)'].replace(0,df['Body mass index (weight in kg/(height in m)^2)'].mean(axis=0),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of times pregnant</th>\n",
       "      <th>Plasma glucose concentration</th>\n",
       "      <th>Diastolic blood pressure (mm Hg)</th>\n",
       "      <th>Triceps skinfold thickness (mm)</th>\n",
       "      <th>2-Hour serum insulin (mu U/ml)</th>\n",
       "      <th>Body mass index (weight in kg/(height in m)^2)</th>\n",
       "      <th>Diabetes pedigree function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Is Diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.400782</td>\n",
       "      <td>121.681605</td>\n",
       "      <td>72.254807</td>\n",
       "      <td>26.606479</td>\n",
       "      <td>94.652344</td>\n",
       "      <td>32.450805</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.984162</td>\n",
       "      <td>30.436016</td>\n",
       "      <td>12.115932</td>\n",
       "      <td>9.631241</td>\n",
       "      <td>105.547598</td>\n",
       "      <td>6.875374</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>99.750000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of times pregnant  Plasma glucose concentration  \\\n",
       "count                768.000000                    768.000000   \n",
       "mean                   4.400782                    121.681605   \n",
       "std                    2.984162                     30.436016   \n",
       "min                    1.000000                     44.000000   \n",
       "25%                    2.000000                     99.750000   \n",
       "50%                    3.845052                    117.000000   \n",
       "75%                    6.000000                    140.250000   \n",
       "max                   17.000000                    199.000000   \n",
       "\n",
       "       Diastolic blood pressure (mm Hg)  Triceps skinfold thickness (mm)  \\\n",
       "count                        768.000000                       768.000000   \n",
       "mean                          72.254807                        26.606479   \n",
       "std                           12.115932                         9.631241   \n",
       "min                           24.000000                         7.000000   \n",
       "25%                           64.000000                        20.536458   \n",
       "50%                           72.000000                        23.000000   \n",
       "75%                           80.000000                        32.000000   \n",
       "max                          122.000000                        99.000000   \n",
       "\n",
       "       2-Hour serum insulin (mu U/ml)  \\\n",
       "count                      768.000000   \n",
       "mean                        94.652344   \n",
       "std                        105.547598   \n",
       "min                         14.000000   \n",
       "25%                         30.500000   \n",
       "50%                         31.250000   \n",
       "75%                        127.250000   \n",
       "max                        846.000000   \n",
       "\n",
       "       Body mass index (weight in kg/(height in m)^2)  \\\n",
       "count                                      768.000000   \n",
       "mean                                        32.450805   \n",
       "std                                          6.875374   \n",
       "min                                         18.200000   \n",
       "25%                                         27.500000   \n",
       "50%                                         32.000000   \n",
       "75%                                         36.600000   \n",
       "max                                         67.100000   \n",
       "\n",
       "       Diabetes pedigree function         Age  Is Diabetic  \n",
       "count                  768.000000  768.000000   768.000000  \n",
       "mean                     0.471876   33.240885     0.348958  \n",
       "std                      0.331329   11.760232     0.476951  \n",
       "min                      0.078000   21.000000     0.000000  \n",
       "25%                      0.243750   24.000000     0.000000  \n",
       "50%                      0.372500   29.000000     0.000000  \n",
       "75%                      0.626250   41.000000     1.000000  \n",
       "max                      2.420000   81.000000     1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the feature and the Label columns \n",
    "x=df.drop(labels='Is Diabetic', axis=1)\n",
    "y= df['Is Diabetic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8)\n",
      "(154, 8)\n",
      "(614,)\n",
      "(154,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.20, random_state = 0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_dataset[most_relevant_features]\n",
    "train_y=train_dataset['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shyam Adsul\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier(objective='binary:logistic')\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246753246753247"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheking training accuracy\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[90 17]\n",
      " [10 37]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       107\n",
      "           1       0.69      0.79      0.73        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.79      0.81      0.80       154\n",
      "weighted avg       0.83      0.82      0.83       154\n",
      "\n",
      "Accuracy: 0.8246753246753247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,y_pred)\n",
    "print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'booster':['gbtree','gblinear'],\n",
    "             'colsample_bytree':[0.4,0.6,0.8,1],\n",
    "             'learning_rate':[0.01,0.1,0.2,0.4],\n",
    "             'max_depth':[2,3,4,6],\n",
    "             'n_estimators':[200,300,400,500],\n",
    "              'subsample':[0.4,0.6,0.8,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= GridSearchCV(XGBClassifier(objective='binary:logistic'), param_grid, verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2048 candidates, totalling 10240 fits\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4 \n",
      "[01:42:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Shyam Adsul\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4, score=0.715, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4 \n",
      "[01:42:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4, score=0.805, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4 \n",
      "[01:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4, score=0.797, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4 \n",
      "[01:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4, score=0.683, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4 \n",
      "[01:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.4, score=0.762, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6 \n",
      "[01:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6, score=0.715, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6 \n",
      "[01:42:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6, score=0.813, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6 \n",
      "[01:42:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6, score=0.805, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6 \n",
      "[01:42:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6, score=0.691, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6 \n",
      "[01:42:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.6, score=0.746, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8 \n",
      "[01:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8, score=0.715, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8 \n",
      "[01:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8, score=0.821, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8 \n",
      "[01:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8, score=0.805, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8 \n",
      "[01:42:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8, score=0.691, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8 \n",
      "[01:42:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8, score=0.746, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1 \n",
      "[01:42:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1, score=0.699, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1 \n",
      "[01:42:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1, score=0.837, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1 \n",
      "[01:42:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1, score=0.789, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1 \n",
      "[01:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1, score=0.699, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1 \n",
      "[01:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1, score=0.746, total=   0.2s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4 \n",
      "[01:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4, score=0.707, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4 \n",
      "[01:42:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4, score=0.805, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4 \n",
      "[01:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4, score=0.797, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4 \n",
      "[01:42:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4, score=0.675, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4 \n",
      "[01:42:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.4, score=0.770, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6 \n",
      "[01:42:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6, score=0.724, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6 \n",
      "[01:42:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6, score=0.846, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6 \n",
      "[01:42:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6, score=0.805, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6 \n",
      "[01:42:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6, score=0.699, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6 \n",
      "[01:42:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.6, score=0.770, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8 \n",
      "[01:42:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8, score=0.724, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8 \n",
      "[01:42:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8, score=0.837, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8 \n",
      "[01:42:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8, score=0.797, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8 \n",
      "[01:42:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8, score=0.691, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8 \n",
      "[01:42:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=0.8, score=0.754, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1 \n",
      "[01:42:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1, score=0.691, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1 \n",
      "[01:42:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1, score=0.837, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1 \n",
      "[01:42:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1, score=0.797, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1 \n",
      "[01:42:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1, score=0.707, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1 \n",
      "[01:42:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=300, subsample=1, score=0.746, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4 \n",
      "[01:42:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4, score=0.699, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4 \n",
      "[01:42:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4, score=0.797, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4 \n",
      "[01:42:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4, score=0.813, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4 \n",
      "[01:42:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4, score=0.675, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4 \n",
      "[01:42:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.4, score=0.770, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6 \n",
      "[01:42:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6, score=0.715, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6 \n",
      "[01:42:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6, score=0.837, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6 \n",
      "[01:42:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6, score=0.797, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6 \n",
      "[01:42:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6, score=0.699, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6 \n",
      "[01:42:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.6, score=0.779, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8 \n",
      "[01:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8, score=0.707, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8 \n",
      "[01:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8, score=0.837, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8 \n",
      "[01:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8, score=0.789, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8 \n",
      "[01:42:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8, score=0.683, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8 \n",
      "[01:42:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=0.8, score=0.762, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1 \n",
      "[01:42:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1, score=0.699, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1 \n",
      "[01:42:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1, score=0.829, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1 \n",
      "[01:42:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1, score=0.789, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1 \n",
      "[01:42:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1, score=0.699, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1 \n",
      "[01:42:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=400, subsample=1, score=0.754, total=   0.4s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4 \n",
      "[01:42:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4, score=0.683, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4 \n",
      "[01:42:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4, score=0.821, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4 \n",
      "[01:42:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4, score=0.797, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4 \n",
      "[01:42:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4, score=0.667, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4 \n",
      "[01:42:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.4, score=0.787, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6 \n",
      "[01:42:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6, score=0.691, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6 \n",
      "[01:42:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6, score=0.829, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6 \n",
      "[01:42:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6, score=0.780, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6 \n",
      "[01:42:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6, score=0.675, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6 \n",
      "[01:42:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.6, score=0.779, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8 \n",
      "[01:42:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8, score=0.699, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8 \n",
      "[01:42:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8, score=0.846, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8 \n",
      "[01:42:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8, score=0.780, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8 \n",
      "[01:42:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8, score=0.667, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8 \n",
      "[01:42:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=0.8, score=0.779, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1 \n",
      "[01:42:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1, score=0.699, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1 \n",
      "[01:42:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1, score=0.829, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1 \n",
      "[01:42:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1, score=0.780, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1 \n",
      "[01:42:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1, score=0.691, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1 \n",
      "[01:42:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=2, n_estimators=500, subsample=1, score=0.779, total=   0.5s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4 \n",
      "[01:42:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4, score=0.699, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4 \n",
      "[01:42:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4, score=0.805, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4 \n",
      "[01:42:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4, score=0.821, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4 \n",
      "[01:42:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4, score=0.683, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4 \n",
      "[01:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.4, score=0.779, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6 \n",
      "[01:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6, score=0.707, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6 \n",
      "[01:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6, score=0.829, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6 \n",
      "[01:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6, score=0.805, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6 \n",
      "[01:42:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6, score=0.699, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6 \n",
      "[01:42:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.6, score=0.770, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[01:42:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8, score=0.699, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[01:42:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8, score=0.813, total=   0.3s\n",
      "[CV] booster=gbtree, colsample_bytree=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8 \n",
      "[01:42:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-807fe847b3e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m                                       *args, **kwargs)\n\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                 \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"best_ntree_limit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 970\u001b[1;33m         class_probs = self.get_booster().predict(\n\u001b[0m\u001b[0;32m    971\u001b[0m             \u001b[0mtest_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[0;32m   1487\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m         _check_call(_LIB.XGBoosterPredict(self.handle, data.handle,\n\u001b[0m\u001b[0;32m   1490\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moption_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_uint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-28c2e4d7952c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { colsample_bylevel, colsample_bynode, colsample_bytree, gamma, interaction_constraints, max_delta_step, max_depth, min_child_weight, monotone_constraints, num_parallel_tree, subsample, tree_method } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:43:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=1, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=500, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new model using the same parameters\n",
    "new_model=XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.4, gamma=1, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=1, max_delta_step=0, max_depth=2,\n",
    "              min_child_weight=1, missing=np.nan, monotone_constraints='()',\n",
    "              n_estimators=500, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "new_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cheking training accuracy\n",
    "y_pred_new = new_model.predict(x_test)\n",
    "predictions_new = [round(value) for value in y_pred]\n",
    "accuracy_new = accuracy_score(y_test,y_pred_new)\n",
    "accuracy_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[99  8]\n",
      " [20 27]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       107\n",
      "           1       0.77      0.57      0.66        47\n",
      "\n",
      "    accuracy                           0.82       154\n",
      "   macro avg       0.80      0.75      0.77       154\n",
      "weighted avg       0.81      0.82      0.81       154\n",
      "\n",
      "Accuracy: 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, y_pred_new)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred_new)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,y_pred_new)\n",
    "print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy: 0.8181818181818182\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
